{% load static %}


<!-- STYLE -->

<link rel="stylesheet" type="text/css" href="{% static 'ui/style.css' %}" />

<style>
.dropzone {
height: 200px;
width: 750px;
border: dashed 1px red;
background-color: lightblue;
}   


p.results {
    padding: 0.75cm 0.0cm 0.1cm 1.0cm;
}

#gpost { 
    visibility: hidden;
}

ul { list-style: none; }

#recordingslist audio { display: block; margin-bottom: 10px; }
</style>



<!-- HTML -->

{% block content %}
<form method="post" action="/upload/" enctype="multipart/form-data" class="dropzone" id="rptdropzone">
  {% csrf_token %}
</form>
{% endblock %}


<p >Hold down any key to record a command.</p>


<ul id="recordingslist"></ul>

<pre id="logpersistent"></pre>
	
	
<!-- debugging -->
<button type="button" id="gpost" onclick="process_request()">Post with current buffers</button>
<!-- -->

<p id="status" class="results"></p>

<p id="response" class="results"></p>

<p id="transcript" class="results"></p>
   
<img id="resultsimg" src="{% static 'ui/placeholder.png' %}" alt="Results (optional)">


<pre id="logdynamic"></pre>
 
 
<!-- JS -->
 
<script src="{% static 'ui/recorder.js' %}"></script>
<script src="{% static 'ui/dropzone.js' %}"></script>
<script src="{% static 'ui/baseencoding.js' %}"></script>

<script>
var glevel = 3; // debug level: 0 (production) - 3 (all output)
var autosend = false; // if true, successful recording is always posted, if false depends on debug level (ie only when glevel == 0)
var pcm16_base64 = '';
var TARGET_SAMPLE_RATE = 16000;
var downsample = true;


function __log(e, data) {
    logpersistent.innerHTML += "\n" + e + " " + (data || '');
  }
function __logdyn(e, data) {
    logdynamic.innerHTML += "\n" + e + " " + (data || '');
  }
function __clearlogdyn() {
    logdynamic.innerHTML = "";
  }
function __transcript(e) {
    document.getElementById("transcript").innerHTML = 'You: \"' + e + '\"';
  }
function __response(e) {
    document.getElementById("response").innerHTML = 'IX: ' + e;
  }
function __status(e) {
    document.getElementById("status").innerHTML = e;
  }
function __image(e) {
    var rimg = document.getElementById("resultsimg");
    
    if(e == "na"){
      document.getElementById('resultsimg').style.visibility = 'hidden';
      
      if(glevel > 2){
      rimg.src = "{% static 'ui/placeholder.png' %}";
        __logdyn("Received no image to display");
      }
      return;
    }
    
    if(glevel > 2){
      __logdyn("Received image to be displayed", e);
    }
    
    rimg.src = e;
    rimg.height = 200;
    document.getElementById('resultsimg').style.visibility = 'visible';
  }
  

Dropzone.options.rptdropzone = {
  paramName: "rptfile",
  maxFiles: 1,
  dictDefaultMessage: "Drop PRT file here",
  maxFilesize: 5,
  init: function() {
    this.on("maxfilesexceeded", function(file) {
              this.removeAllFiles();
              this.addFile(file);
        });
    this.on("success", function(file, responseText) {      
      // TODO check if good? no, because this only happens on success
      localStorage.setItem("url_rpt", responseText["public_url"]);
      if(glevel > 2){
        __logdyn("Set file rpt to ", localStorage.getItem("url_rpt"));
      }
      
      file.previewTemplate.appendChild(document.createTextNode(responseText["public_url"]));
    });
  }
};
 

 
 
function process_request() {
  if(localStorage.getItem("url_rpt") == "")
  {
    __status("No file has been uploaded.");
    return;
  }
  
  
  __status("Posting request.");
  
  var xhttp = new XMLHttpRequest();
  xhttp.onreadystatechange = function() {
    //if (this.readyState == 4 && this.status == 202) {
    if (this.readyState == 4) {  
      __status("Received response.");
      
      var responseJSON = JSON.parse(this.responseText);
      var display_text = responseJSON["response"];
      __response(display_text);
      display_text = responseJSON["url_image"];
      __image(display_text);
      
      if(glevel > 2){
        display_text = responseJSON["transcript"];
        __transcript(display_text);
        }
    }
  };
  xhttp.open("POST", "/inspector/request/", true);
  xhttp.setRequestHeader("Content-Type", "application/json");
  
  // TODO alert if empty, or don't do anything, make dummy that's only overwritten if available
  var url_rpt = localStorage.getItem("url_rpt");    

 
  xhttp.send(JSON.stringify({url_rpt:url_rpt, base64_audio:pcm16_base64})); 
   __status("Waiting for response.");
}



document.body.onkeydown = function(e){
    startRecording();
};
document.body.onkeyup = function(e){
    stopRecording();
};



// https://github.com/mattdiamond/Recorderjs
// http://watson-developer-cloud.github.io/speech-javascript-sdk/master/speech-to-text_webaudio-l16-stream.js.html
  
var audio_context;
var recorder;
var is_recording = false;


// this is being called on startup and initializes recorder
function startUserMedia(stream) {
	var input = audio_context.createMediaStreamSource(stream);
  if(glevel > 1){
    __log('Media stream created.');
  }
	
	recorder = new Recorder(input);
  
  if(glevel > 1){
    __log('Recorder initialised.');
  }
}


function startRecording() {
  __clearlogdyn()

  if(is_recording == false) {
    recorder && recorder.record();
    is_recording = true;
    
    if(glevel > 2){
      __logdyn('Recording...');
    }
  }
}



function sleep(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

async function stopRecording() {
	recorder && recorder.stop();
  
  await sleep(500);
  
  if(glevel > 2){
    __logdyn('Stopped recording.');
  }
    
	is_recording = false;
  
  // for buffers to catch up?

  forwardRecording();
  
  // wav conversion in here
  if(glevel > 2){
    showRecording();	
    }
	
	recorder.clear();
}

// float to pcm: http://watson-developer-cloud.github.io/speech-javascript-sdk/master/speech-to-text_webaudio-l16-stream.js.html
function flt32ToPCM16(flts32){
  var output = new DataView(new ArrayBuffer(flts32.length * 2)); // length is in bytes (8-bit), so number samples *2 to get 16-bit length
  for (var i = 0; i < flts32.length; i++) {
    var multiplier = flts32[i] < 0 ? 0x8000 : 0x7fff; // 16-bit signed range is -32768 to 32767
    output.setInt16(i * 2, flts32[i] * multiplier | 0, true); // index, value, little edian
  }
  return output.buffer; // returns the ArrayBuffer
}


// http://stackoverflow.com/questions/27598270/resample-audio-buffer-from-44100-to-16000
// http://watson-developer-cloud.github.io/speech-javascript-sdk/master/speech-to-text_webaudio-l16-stream.js.html
function downsampleToTarget(flts32){
  // downsampling variables
  var filter = [-0.037935, -0.00089024, 0.040173, 0.019989, 0.0047792, -0.058675, -0.056487,
    -0.0040653, 0.14527, 0.26927, 0.33913, 0.26927, 0.14527, -0.0040653, -0.056487,  -0.058675,
    0.0047792, 0.019989, 0.040173, -0.00089024, -0.037935 ];
    
  var samplingRateRatio = audio_context.sampleRate / TARGET_SAMPLE_RATE;  
  
  
  var nOutputSamples = Math.floor((flts32.length - filter.length) / samplingRateRatio) + 1;
  
  if(glevel > 2){
    __logdyn('Raw sample number ', flts32.length);
    __logdyn('Downsample factor of ', samplingRateRatio);
    __logdyn('Downsample to ', nOutputSamples);
  }
  
  var outputBuffer = new Float32Array(nOutputSamples);
  
  for (i = 0; i + filter.length - 1 < flts32.length; i++) {
    offset = Math.round(samplingRateRatio * i);
    var sample = 0;
    for (var j = 0; j < filter.length; ++j) {
      sample += flts32[offset + j] * filter[j];
    }
    outputBuffer[i] = sample;
  }
  
  return outputBuffer;
}


// mono out of stereo by simple mean
function averageStereo(buffers){

  buffer0 = buffers[0];
  buffer1 = buffers[1];
  
  if(glevel > 2){
    __logdyn('Averaging stereo to mono');
  }  
  
  for (i = 0; i < buffer0.length; i++) {
    buffer0[i] = (buffer0[i]+buffer1[i])/2.0;
  }
  
  return buffer0;
}


// TODO  (before 32->16) x) interleave(and adjust sample rate) 
// interleave: https://github.com/daaain/JSSoundRecorder
function postProcessRecording(){
  recorder && recorder.getBuffer(function(buffers) {
    // for now, we use first channel only
    var buffer = buffers[0];
    
    if(buffers.length == 2){
      buffer = averageStereo(buffers);
    }
    
    if(downsample && buffer.length != 0){
      buffer = downsampleToTarget(buffer);
    }            
    
    // we convert the 4 byte floats to 2 byte pcm
    var pcm16_buffer = flt32ToPCM16(buffer);
    
    // now we need the base64 encoding of the buffer
    pcm16_base64 = base64ArrayBuffer(pcm16_buffer);   
    
    // https://github.com/mattdiamond/Recorderjs
    //var new_buffer = audio_context.createBuffer(2, buffers[0].length, audio_context.sampleRate);
	});
}


// wav export here, don't call in production for performance
function showRecording() {
	recorder && recorder.exportWAV(function(blob) {
		var url = URL.createObjectURL(blob);
		var li = document.createElement('li');
		var au = document.createElement('audio');
		var hf = document.createElement('a');
		
		au.controls = true;
		au.src = url;
		hf.href = url;
		hf.download = new Date().toISOString() + '.wav';
		//hf.innerHTML = hf.download;
		li.appendChild(au);
		li.appendChild(hf);
		
    while(recordingslist.firstChild){
      		recordingslist.removeChild(recordingslist.firstChild);
    }

		recordingslist.appendChild(li);
	});
}


function forwardRecording(){

  postProcessRecording();  
  
  if(glevel > 2){
    __logdyn('PCM 16 base64 encoded size', pcm16_base64.length);
  }
  
  if(glevel == 0 || autosend)
  {
    if(pcm16_base64.length > 0)
    {
      process_request();      
    }
    else{
      __status("Recording empty");
    }
  }
}

// all init things go in here
window.onload = function init() {

  // empty default file name
  localStorage.setItem("url_rpt", "");
  
  
  document.getElementById('resultsimg').style.visibility = 'hidden';
  
  // enable debug elements
  if(glevel > 0){
  
    
    document.getElementById('gpost').style.visibility = 'visible';
    
    __log('This is a debug version with high verbosity.');
    __log('Debug level: ', glevel);
    if(autosend){
      __log('Autosend successful recording enabled');
      }
      else{
      __log('Autosend successful recording disabled');
      }
  }
  
	try {
		// webkit shim
		window.AudioContext = window.AudioContext || window.webkitAudioContext;
		navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia;
		window.URL = window.URL || window.webkitURL;
		
		audio_context = new AudioContext;
    
    if(glevel > 1){
      __log('Audio context set up.');
      __log('JS navigator.getUserMedia ' + (navigator.getUserMedia ? 'available.' : 'not present!'));
    }
	} catch (e) {
		alert('No web audio support in this browser!');
	}
	
	navigator.getUserMedia({audio: true}, startUserMedia, function(e) {
    if(glevel > 1){
      __log('No live audio input: ' + e);
    }
	});
};
</script>


